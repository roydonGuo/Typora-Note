# 大数据最新2022年面试题及答案，汇总版


### 全部答案，更新日期：2022年5月18日，直接下载吧！

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://gitee.com/souyunku/DevBooks/blob/master/docs/index.md)



### [1、请用java实现非递归二分查询](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#1请用java实现非递归二分查询)  


```
public class BinarySearchClass

{

public static int binary_search(int[] array, int value)

{

 int beginIndex = 0;// 低位下标

 int endIndex = array.length - 1;// 高位下标

 int midIndex = -1;

 while (beginIndex <= endIndex) {

     midIndex = beginIndex + (endIndex - beginIndex) / 2;//防止溢出

     if (value == array[midIndex]) {

         return midIndex;

     } else if (value < array[midIndex]) {

         endIndex = midIndex - 1;

     } else {

         beginIndex = midIndex + 1;

     }

 }

 return -1;

 //找到了，返回找到的数值的下标，没找到，返回-1

}

//start 提示：自动阅卷起始唯一标识，请勿删除或增加。

public static void main(String[] args)

{

 System.out.println("Start...");

 int[] myArray = new int[] { 1, 2, 3, 5, 6, 7, 8, 9 };

 System.out.println("查找数字8的下标：");

 System.out.println(binary_search(myArray, 8));

}

//end //提示：自动阅卷结束唯一标识，请勿删除或增加。

}
```


### [2、是客户端还是Namenode决定输入的分片？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#2是客户端还是namenode决定输入的分片)  


这并不是客户端决定的，在配置文件中以及决定分片细则。


### [3、mapred.job.tracker命令的作用？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#3mapredjobtracker命令的作用)  


可以让你知道哪个节点是Job Tracker。


### [4、全分布模式又有什么注意点？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#4全分布模式又有什么注意点)  


全分布模式通常被用于生产环境，这里我们使用N台主机组成一个Hadoop集群，Hadoop守护进程运行在每台主机之上。这里会存在Namenode运行的主机，Datanode运行的主机，以及task tracker运行的主机。在分布式环境下，主节点和从节点会分开。


### [5、hive 跟hbase的区别](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#5hive-跟hbase的区别)  


共同点都是用hadoop作为底层存储

区别：hive是为了减少mrjobs编写工作的批处理系统，处理速度慢。hive本身不存储数据和计算数据，依赖于hadoop，纯逻辑表

hbase是为了hadoop对实时操作的缺陷的项目，处理速度快，是物理表，提供一个超大的内存hash表，方便查询操作

如果全表扫描用 hive+hadoop

如果用索引查询与hbase+hadoop

是处理数据库文件还是读取文本文件

先读取文本文件进行清洗，然后放入hdfs，进行处理

或者直接读取MySQL中格式化数据


### [6、请列出正常工作的hadoop集群中hadoop都需要启动哪些进程，他们的作用分别是什么？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#6请列出正常工作的hadoop集群中hadoop都需要启动哪些进程他们的作用分别是什么)  


NameNode: HDFS的守护进程，负责记录文件是如何分割成数据块，以及这些数据块分别被存储到那些数据节点上，它的主要功能是对内存及IO进行集中管理

Secondary NameNode：辅助后台程序，与NameNode进行通信，以便定期保存HDFS元数据的快照。

DataNode：负责把HDFS数据块读写到本地的文件系统。

JobTracker：负责分配task，并监控所有运行的task。

TaskTracker：负责执行具体的task，并与JobTracker进行交互。


### [7、KafkaUtils.createDstream 和 KafkaUtils.createDirectstream 区别](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#7kafkautilscreatedstream-和-kafkautilscreatedirectstream-区别)  


使用一个 receiver 接收器接收数据，接收到的数据将会保存到executor中，然后通过sparkStreaming 启动job来处理数据，默认不会丢失，可启动WAL日志，保存到hdfs上

spark.streaming.recever.writeAheadLog.enable=true 同时开启 StorageLevel.MeMORY_AND_DISK_SER_2

KafkaUtils.createDirectstream方式，他定期从Kafka的分区中查询偏移量，再根据偏移量范围在每个batch里面处理数据

优点：简化并行 高效 恰好一次被消费

hbase


### [8、Kafka与传统消息队列的区别](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#8kafka与传统消息队列的区别)  


RabbitMQ吞吐量稍差Kafka，支持对消息可靠的传递，支持事务，不支持批量的操作，存储于内存或者磁盘

Kafka遵从一般的MQ结构，producer，broker，consumer，以consumer为中心，消费的消费信息保存在客户端consumer上，consumer根据消费的点，从broker批量pull数据；无消息确认机制

Kafka具有搞得吞吐量，内部采用消息的批量处理，数据的存储和获取是本地磁盘顺序批量操作，消息处理的效率高

Kafka 的broker支持主备模式

Kafka 负载均衡 Zookeeper方向

Kafka采用Zookeeper进行管理，可以注册topic到Zookeeper上，通过zoo的协调机制，生产者保存对应topic的broker消息，可以随机或者轮询发送到broker上；并且生产者可以基于予以定义指定分片，消息发送到broker的某分片上


### [9、Master文件是否提供了多个入口？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#9master文件是否提供了多个入口)  


是的你可以拥有多个Master文件接口。


### [10、Spark的数据本地性有哪几种？](https://gitee.com/souyunku/DevBooks/blob/master/docs/大数据/大数据最新2021年面试题及答案，汇总版.md#10spark的数据本地性有哪几种)  


Spark中的数据本地性有三种：

**1、** PROCESS_LOCAL是指读取缓存在本地节点的数据

**2、** NODE_LOCAL是指读取本地节点硬盘数据

**3、** ANY是指读取非本地节点数据

通常读取数据PROCESS_LOCAL>NODE_LOCAL>ANY，尽量使数据以PROCESS_LOCAL或NODE_LOCAL方式读取。其中PROCESS_LOCAL还和cache有关，如果RDD经常用的话将该RDD cache到内存中，注意，由于cache是lazy的，所以必须通过一个action的触发，才能真正的将该RDD cache到内存中。


### 11、Spark的shuffle过程？
### 12、fsimage和edit的区别？
### 13、List与set的区别
### 14、海量日志数据，提取出某日访问百度次数最多的那个IP。
### 15、storm特点
### 16、Hbase宕机如何处理
### 17、Hbase行键列族的概念，物理模型，表的设计原则？
### 18、Spark为什么要持久化，一般什么场景下要进行persist操作？
### 19、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。
### 20、SSH中的注意点还包括？
### 21、存储特点
### 22、请简述hadoop怎样实现二级排序（就是对key和value双排序）
### 23、现场出问题测试mapreduce掌握情况和hive的ql语言掌握情况
### 24、hadoop数据倾斜及解决办法
### 25、HDFS读取文件的步骤
### 26、sqoop在导入到MySQL中，如果不重复导入数据，如果数据存在问题，sqoop如何处理？
### 27、什么是udf
### 28、hadoop的TextInputFormat作用是什么，如何自定义实现？
### 29、hbase内部机制是什么
### 30、如何退出输入模式？
### 31、简述hadoop spark storm hive的特点及使用场景
### 32、combine出现在哪个过程





## [全部答案，更新日期：2022年5月18日，直接下载吧！](https://gitee.com/souyunku/DevBooks/blob/master/docs/daan.md)

### 下载链接：[全部答案，整理好了](https://gitee.com/souyunku/DevBooks/blob/master/docs/daan.md)




## [新增：高清PDF：172份，7701页，最新整理](https://gitee.com/souyunku/DevBooks/blob/master/docs/daan.md)




